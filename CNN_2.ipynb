{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognizer with CNN\n",
    "\n",
    "In this notebook, we build and evaluate a Convolutional Neural Network (CNN) to recognize hand-drawn digits from the MNIST-like dataset provided by Kaggle's Digit Recognizer competition. Our objective is to preprocess the training data, augment it, and use a CNN to train a model capable of accurately predicting the digits in the test set. Finally, we format and save the predictions for submission in the required Kaggle format. The steps include data preparation, model training, data augmentation, and evaluation on the validation set before making predictions on the test set.\n",
    "\n",
    "## First Part - Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Loading the Training Data**\n",
    "Here, we load the `train.csv` and `test.csv` files containing the images of digits and their associated labels. The images are stored as pixel values, and the labels represent the drawn digits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Preparing the Data**\n",
    "The images are resized and normalized to make them compatible with the model (values between 0 and 1). We also perform reshaping to ensure the images have the correct shape (`28x28x1`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_df.iloc[:, 1:].values\n",
    "train_labels = train_df.iloc[:, 0].values\n",
    "\n",
    "test_images = test_df.values\n",
    "\n",
    "train_images = train_images.reshape((-1, 28, 28, 1)).astype('float32') / 255\n",
    "test_images = test_images.reshape((-1, 28, 28, 1)).astype('float32') / 255\n",
    "\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(\n",
    "    train_images, train_labels, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Splitting the Data into Training and Validation Sets**\n",
    "We split the training data into two subsets: one for training and one for validation. This allows us to check the model's performance during training on data it has not seen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, val_images, train_labels, val_labels = train_test_split(\n",
    "    train_images, train_labels, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Defining the ImageDataGenerator for Data Augmentation**\n",
    "We use `ImageDataGenerator` to apply transformations to the images during training. These transformations include rotation, translation, zoom, and more, which helps increase the diversity of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,  # Rotation de -10 à +10 degrés\n",
    "    width_shift_range=0.1,  # Déplacement horizontal\n",
    "    height_shift_range=0.1,  # Déplacement vertical\n",
    "    zoom_range=0.1,  # Zoom entre 90% et 110%\n",
    "    shear_range=0.1,  # Décalage (shear)\n",
    "    horizontal_flip=False,  # Pas de retournement horizontal\n",
    "    fill_mode='nearest'  # Compléter les pixels manquants par la valeur la plus proche\n",
    ")\n",
    "\n",
    "datagen.fit(train_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Defining the Model**\n",
    "We define a convolutional neural network (CNN) with two convolutional layers, two pooling layers, a flatten layer, and a final dense layer with 10 neurons to predict digits from 0 to 9.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Compiling the Model**\n",
    "We compile the model using the `Adam` optimizer and the `sparse_categorical_crossentropy` loss function, which is suited for multi-class classification problems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Training the Model with Data Augmentation**\n",
    "We train the model using the data augmentation generator. Each epoch will see new variations of the images thanks to augmentation, helping improve the model's generalization ability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "420/420 [==============================] - 11s 24ms/step - loss: 0.6226 - accuracy: 0.7980 - val_loss: 0.1865 - val_accuracy: 0.9421\n",
      "Epoch 2/10\n",
      "420/420 [==============================] - 10s 24ms/step - loss: 0.2532 - accuracy: 0.9207 - val_loss: 0.1456 - val_accuracy: 0.9540\n",
      "Epoch 3/10\n",
      "420/420 [==============================] - 10s 25ms/step - loss: 0.1836 - accuracy: 0.9430 - val_loss: 0.1037 - val_accuracy: 0.9649\n",
      "Epoch 4/10\n",
      "420/420 [==============================] - 10s 24ms/step - loss: 0.1562 - accuracy: 0.9499 - val_loss: 0.1142 - val_accuracy: 0.9640\n",
      "Epoch 5/10\n",
      "420/420 [==============================] - 10s 24ms/step - loss: 0.1293 - accuracy: 0.9592 - val_loss: 0.0742 - val_accuracy: 0.9743\n",
      "Epoch 6/10\n",
      "420/420 [==============================] - 11s 26ms/step - loss: 0.1253 - accuracy: 0.9611 - val_loss: 0.0733 - val_accuracy: 0.9756\n",
      "Epoch 7/10\n",
      "420/420 [==============================] - 11s 26ms/step - loss: 0.1149 - accuracy: 0.9621 - val_loss: 0.0648 - val_accuracy: 0.9793\n",
      "Epoch 8/10\n",
      "420/420 [==============================] - 11s 26ms/step - loss: 0.1052 - accuracy: 0.9665 - val_loss: 0.0540 - val_accuracy: 0.9818\n",
      "Epoch 9/10\n",
      "420/420 [==============================] - 11s 27ms/step - loss: 0.0968 - accuracy: 0.9692 - val_loss: 0.0694 - val_accuracy: 0.9778\n",
      "Epoch 10/10\n",
      "420/420 [==============================] - 11s 27ms/step - loss: 0.0908 - accuracy: 0.9710 - val_loss: 0.0597 - val_accuracy: 0.9810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1763d8784c0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(datagen.flow(train_images, train_labels, batch_size=64), epochs=10, validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model\n",
    "After training, we evaluate the model's performance on the validation set. This helps us understand the accuracy and generalization capabilities of the model.\n",
    "\n",
    "### Making Predictions on Test Data\n",
    "With the trained model, we make predictions on the test dataset. Each image is classified into one of the ten digit classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875/875 [==============================] - 3s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_images)\n",
    "predicted_classes = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({\n",
    "    'ImageId': np.arange(1, len(predicted_classes) + 1),\n",
    "    'Label': predicted_classes\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Submission File\n",
    "We prepare the submission file by associating each test image with its predicted label. The submission file is formatted as required by Kaggle: each row contains an ImageId and the corresponding predicted Label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({\n",
    "    'ImageId': np.arange(1, len(predicted_classes) + 1),\n",
    "    'Label': predicted_classes\n",
    "})\n",
    "\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "This code prepares the training data, applies real-time data augmentation during training, trains a convolutional neural network model, and saves the model for future use. Key steps include normalizing the images, splitting the data into training and validation sets, and applying data augmentation during training to improve model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
