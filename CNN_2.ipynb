{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognizer with CNN\n",
    "\n",
    "In this notebook, we build and evaluate a Convolutional Neural Network (CNN) to recognize hand-drawn digits from the MNIST-like dataset provided by Kaggle's Digit Recognizer competition. Our objective is to preprocess the training data, augment it, and use a CNN to train a model capable of accurately predicting the digits in the test set. Finally, we format and save the predictions for submission in the required Kaggle format. The steps include data preparation, model training, data augmentation, and evaluation on the validation set before making predictions on the test set.\n",
    "\n",
    "## First Part - Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Loading the Training Data**\n",
    "Here, we load the `train.csv` and `test.csv` files containing the images of digits and their associated labels. The images are stored as pixel values, and the labels represent the drawn digits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Preparing the Data**\n",
    "The images are resized and normalized to make them compatible with the model (values between 0 and 1). We also perform reshaping to ensure the images have the correct shape (`28x28x1`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_df.iloc[:, 1:].values\n",
    "train_labels = train_df.iloc[:, 0].values\n",
    "\n",
    "test_images = test_df.values\n",
    "\n",
    "train_images = train_images.reshape((-1, 28, 28, 1)).astype('float32') / 255\n",
    "test_images = test_images.reshape((-1, 28, 28, 1)).astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Splitting the Data into Training and Validation Sets**\n",
    "We split the training data into two subsets: one for training and one for validation. This allows us to check the model's performance during training on data it has not seen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, val_images, train_labels, val_labels = train_test_split(\n",
    "    train_images, train_labels, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Defining the ImageDataGenerator for Data Augmentation**\n",
    "We use `ImageDataGenerator` to apply transformations to the images during training. These transformations include rotation, translation, zoom, and more, which helps increase the diversity of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,  # Rotation de -10 à +10 degrés\n",
    "    width_shift_range=0.1,  # Déplacement horizontal\n",
    "    height_shift_range=0.1,  # Déplacement vertical\n",
    "    zoom_range=0.1,  # Zoom entre 90% et 110%\n",
    "    shear_range=0.1,  # Décalage (shear)\n",
    "    horizontal_flip=False,  # Pas de retournement horizontal\n",
    "    fill_mode='nearest'  # Compléter les pixels manquants par la valeur la plus proche\n",
    ")\n",
    "\n",
    "datagen.fit(train_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Model\n",
    "\n",
    "In this enhanced approach, we define a convolutional neural network (CNN) with multiple convolutional layers, each followed by batch normalization and dropout for improved stability and regularization. MaxPooling layers are used to reduce spatial dimensions, and the network concludes with a dense layer of 10 neurons, corresponding to the digits from 0 to 9. L2 regularization is applied to the dense layer to prevent overfitting, and a learning rate scheduler is employed to optimize the training process dynamically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), input_shape=(28, 28, 1), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    Conv2D(64, (3, 3), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(128),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Compiling the Model**\n",
    "We compile the model using the `Adam` optimizer and the `sparse_categorical_crossentropy` loss function, which is suited for multi-class classification problems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Training the Model with Data Augmentation**\n",
    "We train the model using the data augmentation generator. Each epoch will see new variations of the images thanks to augmentation, helping improve the model's generalization ability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "525/525 [==============================] - 22s 40ms/step - loss: 0.2202 - accuracy: 0.9377 - val_loss: 1.0395 - val_accuracy: 0.6602\n",
      "Epoch 2/10\n",
      "525/525 [==============================] - 21s 39ms/step - loss: 0.0871 - accuracy: 0.9754 - val_loss: 0.0640 - val_accuracy: 0.9794\n",
      "Epoch 3/10\n",
      "525/525 [==============================] - 22s 41ms/step - loss: 0.0670 - accuracy: 0.9795 - val_loss: 0.0582 - val_accuracy: 0.9801\n",
      "Epoch 4/10\n",
      "525/525 [==============================] - 22s 42ms/step - loss: 0.0549 - accuracy: 0.9844 - val_loss: 0.0418 - val_accuracy: 0.9863\n",
      "Epoch 5/10\n",
      "525/525 [==============================] - 22s 43ms/step - loss: 0.0516 - accuracy: 0.9844 - val_loss: 0.0315 - val_accuracy: 0.9901\n",
      "Epoch 6/10\n",
      "525/525 [==============================] - 22s 42ms/step - loss: 0.0447 - accuracy: 0.9868 - val_loss: 0.0398 - val_accuracy: 0.9871\n",
      "Epoch 7/10\n",
      "525/525 [==============================] - 22s 42ms/step - loss: 0.0438 - accuracy: 0.9873 - val_loss: 0.0717 - val_accuracy: 0.9773\n",
      "Epoch 8/10\n",
      "525/525 [==============================] - 22s 42ms/step - loss: 0.0409 - accuracy: 0.9875 - val_loss: 0.0506 - val_accuracy: 0.9833\n",
      "Epoch 9/10\n",
      "525/525 [==============================] - 22s 42ms/step - loss: 0.0390 - accuracy: 0.9877 - val_loss: 0.0377 - val_accuracy: 0.9880\n",
      "Epoch 10/10\n",
      "525/525 [==============================] - 22s 43ms/step - loss: 0.0375 - accuracy: 0.9884 - val_loss: 0.0386 - val_accuracy: 0.9890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x16fb6a96940>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(datagen.flow(train_images, train_labels, batch_size=64), epochs=10, validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model\n",
    "After training, we evaluate the model's performance on the validation set. This helps us understand the accuracy and generalization capabilities of the model.\n",
    "\n",
    "### Making Predictions on Test Data\n",
    "With the trained model, we make predictions on the test dataset. Each image is classified into one of the ten digit classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875/875 [==============================] - 6s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_images)\n",
    "predicted_classes = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({\n",
    "    'ImageId': np.arange(1, len(predicted_classes) + 1),\n",
    "    'Label': predicted_classes\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Submission File\n",
    "We prepare the submission file by associating each test image with its predicted label. The submission file is formatted as required by Kaggle: each row contains an ImageId and the corresponding predicted Label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({\n",
    "    'ImageId': np.arange(1, len(predicted_classes) + 1),\n",
    "    'Label': predicted_classes\n",
    "})\n",
    "\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "This code prepares the training data, applies real-time data augmentation during training, trains a convolutional neural network model, and saves the model for future use. Key steps include normalizing the images, splitting the data into training and validation sets, and applying data augmentation during training to improve model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
