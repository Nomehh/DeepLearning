{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognizer with CNN\n",
    "In this notebook, we build and evaluate a Convolutional Neural Network (CNN) to recognize hand-drawn digits from the MNIST-like dataset provided by Kaggle's Digit Recognizer competition. The goal is to achieve accurate predictions on the test set and submit the results in the required format.\n",
    "\n",
    "## First Part - Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Dataset\n",
    "We begin by loading the training and test datasets from CSV files. The training set contains labeled data, while the test set is used for making predictions without labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "The data consists of 28x28 grayscale images flattened into a single row of 784 pixel values. We reshape the data into its original 2D format, normalize the pixel values to the range [0, 1], and prepare the labels for training by converting them to categorical format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_df.iloc[:, 1:].values\n",
    "train_labels = train_df.iloc[:, 0].values\n",
    "\n",
    "test_images = test_df.values\n",
    "\n",
    "train_images = train_images.reshape((-1, 28, 28, 1)).astype('float32') / 255\n",
    "test_images = test_images.reshape((-1, 28, 28, 1)).astype('float32') / 255\n",
    "\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Data\n",
    "To validate our model, we split the training data into a training set and a validation set. This will help us monitor the model's performance on unseen data during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the CNN Model\n",
    "We construct a Convolutional Neural Network (CNN) using TensorFlow and Keras. The model includes convolutional layers, max-pooling layers, and dense layers to effectively learn the features of the digit images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the Model\n",
    "We compile the CNN model with the Adam optimizer and categorical crossentropy loss function. The accuracy metric is used to monitor the performance during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "We train the model on the training data for several epochs, with batch size 64. The validation set is used to check for overfitting and to ensure the model generalizes well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "525/525 [==============================] - 11s 20ms/step - loss: 0.2549 - accuracy: 0.9209 - val_loss: 0.0863 - val_accuracy: 0.9720\n",
      "Epoch 2/5\n",
      "525/525 [==============================] - 10s 19ms/step - loss: 0.0654 - accuracy: 0.9799 - val_loss: 0.0651 - val_accuracy: 0.9799\n",
      "Epoch 3/5\n",
      "525/525 [==============================] - 10s 19ms/step - loss: 0.0454 - accuracy: 0.9857 - val_loss: 0.0421 - val_accuracy: 0.9862\n",
      "Epoch 4/5\n",
      "525/525 [==============================] - 10s 20ms/step - loss: 0.0341 - accuracy: 0.9899 - val_loss: 0.0406 - val_accuracy: 0.9876\n",
      "Epoch 5/5\n",
      "525/525 [==============================] - 20s 37ms/step - loss: 0.0289 - accuracy: 0.9912 - val_loss: 0.0447 - val_accuracy: 0.9854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1e0a850fbb0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Part - Evaluating the Model\n",
    "\n",
    "### Making Predictions on Test Data\n",
    "With the trained model, we make predictions on the test dataset. Each image is classified into one of the ten digit classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875/875 [==============================] - 7s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_images)\n",
    "predicted_classes = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({\n",
    "    'ImageId': np.arange(1, len(predicted_classes) + 1),\n",
    "    'Label': predicted_classes\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Submission File\n",
    "We prepare the submission file by associating each test image with its predicted label. The submission file is formatted as required by Kaggle: each row contains an ImageId and the corresponding predicted Label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({\n",
    "    'ImageId': np.arange(1, len(predicted_classes) + 1),\n",
    "    'Label': predicted_classes\n",
    "})\n",
    "\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "In this notebook, we successfully built a CNN to recognize hand-drawn digits with high accuracy. The model was trained, validated, and used to predict the labels of test images. The predictions are saved in a submission file ready for evaluation on Kaggle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
